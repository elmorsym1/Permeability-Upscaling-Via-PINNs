{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Compile predicted data L1 to L2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Custome Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_rotate(data):\n",
    "    data_len = len(data[\"KX\"])\n",
    "    # create extended data\n",
    "    column_list = data.columns.values.tolist()\n",
    "    zero_data = np.zeros(shape=(len(data),len(column_list)))\n",
    "    zero_data = pd.DataFrame(zero_data, columns=column_list)\n",
    "    data_ext = pd.concat([data, zero_data, zero_data], ignore_index=True)\n",
    "    # Rotate and combine data\n",
    "    # large K dataset\n",
    "    data_ext['KX'] = pd.concat([data['KX'], data['KY'], data['KZ']], ignore_index=True)\n",
    "    # small k in X Directions\n",
    "    data_ext['kx1'] = pd.concat([data['kx1'], data['ky1'], data['kz1']], ignore_index=True)\n",
    "    data_ext['kx2'] = pd.concat([data['kx2'], data['ky5'], data['kz2']], ignore_index=True)\n",
    "    data_ext['kx3'] = pd.concat([data['kx3'], data['ky3'], data['kz5']], ignore_index=True)\n",
    "    data_ext['kx4'] = pd.concat([data['kx4'], data['ky7'], data['kz6']], ignore_index=True)\n",
    "    data_ext['kx5'] = pd.concat([data['kx5'], data['ky2'], data['kz3']], ignore_index=True)\n",
    "    data_ext['kx6'] = pd.concat([data['kx6'], data['ky6'], data['kz4']], ignore_index=True)\n",
    "    data_ext['kx7'] = pd.concat([data['kx7'], data['ky4'], data['kz7']], ignore_index=True)\n",
    "    data_ext['kx8'] = pd.concat([data['kx8'], data['ky8'], data['kz8']], ignore_index=True)\n",
    "    # small k in Y Directions\n",
    "    data_ext['ky1'] = pd.concat([data['ky1'], data['kx1'], data['ky1']], ignore_index=True)\n",
    "    data_ext['ky2'] = pd.concat([data['ky2'], data['kx5'], data['ky2']], ignore_index=True)\n",
    "    data_ext['ky3'] = pd.concat([data['ky3'], data['kx3'], data['ky5']], ignore_index=True)\n",
    "    data_ext['ky4'] = pd.concat([data['ky4'], data['kx7'], data['ky6']], ignore_index=True)\n",
    "    data_ext['ky5'] = pd.concat([data['ky5'], data['kx2'], data['ky3']], ignore_index=True)\n",
    "    data_ext['ky6'] = pd.concat([data['ky6'], data['kx6'], data['ky4']], ignore_index=True)\n",
    "    data_ext['ky7'] = pd.concat([data['ky7'], data['kx4'], data['ky7']], ignore_index=True)\n",
    "    data_ext['ky8'] = pd.concat([data['ky8'], data['kx8'], data['ky8']], ignore_index=True)\n",
    "    # small k in Z Directions\n",
    "    data_ext['kz1'] = pd.concat([data['kz1'], data['kz1'], data['kx1']], ignore_index=True)\n",
    "    data_ext['kz2'] = pd.concat([data['kz2'], data['kz5'], data['kx2']], ignore_index=True)\n",
    "    data_ext['kz3'] = pd.concat([data['kz3'], data['kz3'], data['kx5']], ignore_index=True)\n",
    "    data_ext['kz4'] = pd.concat([data['kz4'], data['kz7'], data['kx6']], ignore_index=True)\n",
    "    data_ext['kz5'] = pd.concat([data['kz5'], data['kz2'], data['kx3']], ignore_index=True)\n",
    "    data_ext['kz6'] = pd.concat([data['kz6'], data['kz6'], data['kx4']], ignore_index=True)\n",
    "    data_ext['kz7'] = pd.concat([data['kz7'], data['kz4'], data['kx7']], ignore_index=True)\n",
    "    data_ext['kz8'] = pd.concat([data['kz8'], data['kz8'], data['kx8']], ignore_index=True)\n",
    "    # porosity\n",
    "    data_ext['P'] = pd.concat([data['P'], data['P'], data['P']], ignore_index=True)\n",
    "    data_ext['p1'] = pd.concat([data['p1'], data['p1'], data['p1']], ignore_index=True)\n",
    "    data_ext['p2'] = pd.concat([data['p2'], data['p5'], data['p2']], ignore_index=True)\n",
    "    data_ext['p3'] = pd.concat([data['p3'], data['p3'], data['p5']], ignore_index=True)\n",
    "    data_ext['p4'] = pd.concat([data['p4'], data['p7'], data['p6']], ignore_index=True)\n",
    "    data_ext['p5'] = pd.concat([data['p5'], data['p2'], data['p3']], ignore_index=True)\n",
    "    data_ext['p6'] = pd.concat([data['p6'], data['p6'], data['p4']], ignore_index=True)\n",
    "    data_ext['p7'] = pd.concat([data['p7'], data['p4'], data['p7']], ignore_index=True)\n",
    "    data_ext['p8'] = pd.concat([data['p8'], data['p8'], data['p8']], ignore_index=True)\n",
    "    # eff. porosity\n",
    "    data_ext['EP'] = pd.concat([data['EP'], data['EP'], data['EP']], ignore_index=True)\n",
    "    data_ext['ep1'] = pd.concat([data['ep1'], data['ep1'], data['ep1']], ignore_index=True)\n",
    "    data_ext['ep2'] = pd.concat([data['ep2'], data['ep5'], data['ep2']], ignore_index=True)\n",
    "    data_ext['ep3'] = pd.concat([data['ep3'], data['ep3'], data['ep5']], ignore_index=True)\n",
    "    data_ext['ep4'] = pd.concat([data['ep4'], data['ep7'], data['ep6']], ignore_index=True)\n",
    "    data_ext['ep5'] = pd.concat([data['ep5'], data['ep2'], data['ep3']], ignore_index=True)\n",
    "    data_ext['ep6'] = pd.concat([data['ep6'], data['ep6'], data['ep4']], ignore_index=True)\n",
    "    data_ext['ep7'] = pd.concat([data['ep7'], data['ep4'], data['ep7']], ignore_index=True)\n",
    "    data_ext['ep8'] = pd.concat([data['ep8'], data['ep8'], data['ep8']], ignore_index=True)\n",
    "    # case-name\n",
    "    data_ext['case-name'] = pd.concat([data['case-name'], data['case-name'], data['case-name']], ignore_index=True)\n",
    "    # add directions\n",
    "    data_ext.rename(columns = {'KY':'direction'}, inplace = True)\n",
    "    ones = pd.Series(np.ones(data_len))\n",
    "    data_ext['direction'] = pd.concat([ones, ones*2, ones*3], ignore_index=True)\n",
    "    # drop remaining features\n",
    "    data_ext = data_ext.drop(columns=['KZ', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8'])\n",
    "    \n",
    "    return data_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data - Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case-name</th>\n",
       "      <th>Porosity</th>\n",
       "      <th>Eff. Porosity</th>\n",
       "      <th>K(x)[D]</th>\n",
       "      <th>K(y)[D]</th>\n",
       "      <th>K(z)[D]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192573</td>\n",
       "      <td>0.186276</td>\n",
       "      <td>1.370518</td>\n",
       "      <td>1.341323</td>\n",
       "      <td>1.406573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.193239</td>\n",
       "      <td>0.190980</td>\n",
       "      <td>1.688085</td>\n",
       "      <td>1.431300</td>\n",
       "      <td>1.740610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.202113</td>\n",
       "      <td>0.199161</td>\n",
       "      <td>1.656004</td>\n",
       "      <td>1.772880</td>\n",
       "      <td>1.886217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.214707</td>\n",
       "      <td>0.212279</td>\n",
       "      <td>1.862628</td>\n",
       "      <td>2.201888</td>\n",
       "      <td>2.494776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.211278</td>\n",
       "      <td>0.208762</td>\n",
       "      <td>1.976658</td>\n",
       "      <td>2.482610</td>\n",
       "      <td>2.310467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case-name  Porosity  Eff. Porosity   K(x)[D]   K(y)[D]   K(z)[D]\n",
       "0        1.0  0.192573       0.186276  1.370518  1.341323  1.406573\n",
       "1        3.0  0.193239       0.190980  1.688085  1.431300  1.740610\n",
       "2        5.0  0.202113       0.199161  1.656004  1.772880  1.886217\n",
       "3       13.0  0.214707       0.212279  1.862628  2.201888  2.494776\n",
       "4       15.0  0.211278       0.208762  1.976658  2.482610  2.310467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case-name</th>\n",
       "      <th>Porosity</th>\n",
       "      <th>Eff. Porosity</th>\n",
       "      <th>K(x)[D]</th>\n",
       "      <th>K(y)[D]</th>\n",
       "      <th>K(z)[D]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203290</td>\n",
       "      <td>0.195858</td>\n",
       "      <td>2.0640</td>\n",
       "      <td>2.3188</td>\n",
       "      <td>2.2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.200972</td>\n",
       "      <td>0.193614</td>\n",
       "      <td>2.0488</td>\n",
       "      <td>2.2914</td>\n",
       "      <td>2.2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.201519</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>2.0148</td>\n",
       "      <td>2.2800</td>\n",
       "      <td>2.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.202835</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>2.0999</td>\n",
       "      <td>2.3295</td>\n",
       "      <td>2.2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.201671</td>\n",
       "      <td>0.193953</td>\n",
       "      <td>2.0351</td>\n",
       "      <td>2.2749</td>\n",
       "      <td>2.1776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case-name  Porosity  Eff. Porosity  K(x)[D]  K(y)[D]  K(z)[D]\n",
       "0          1  0.203290       0.195858   2.0640   2.3188   2.2892\n",
       "1          3  0.200972       0.193614   2.0488   2.2914   2.2151\n",
       "2          5  0.201519       0.193641   2.0148   2.2800   2.1974\n",
       "3          7  0.202835       0.195556   2.0999   2.3295   2.2449\n",
       "4          9  0.201671       0.193953   2.0351   2.2749   2.1776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case-name</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>205</td>\n",
       "      <td>217</td>\n",
       "      <td>3469</td>\n",
       "      <td>3481</td>\n",
       "      <td>3673</td>\n",
       "      <td>3685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>206</td>\n",
       "      <td>218</td>\n",
       "      <td>3470</td>\n",
       "      <td>3482</td>\n",
       "      <td>3674</td>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>207</td>\n",
       "      <td>219</td>\n",
       "      <td>3471</td>\n",
       "      <td>3483</td>\n",
       "      <td>3675</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>208</td>\n",
       "      <td>220</td>\n",
       "      <td>3472</td>\n",
       "      <td>3484</td>\n",
       "      <td>3676</td>\n",
       "      <td>3688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>209</td>\n",
       "      <td>221</td>\n",
       "      <td>3473</td>\n",
       "      <td>3485</td>\n",
       "      <td>3677</td>\n",
       "      <td>3689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case-name  c1  c2   c3   c4    c5    c6    c7    c8\n",
       "0          1   1  13  205  217  3469  3481  3673  3685\n",
       "1          2   2  14  206  218  3470  3482  3674  3686\n",
       "2          3   3  15  207  219  3471  3483  3675  3687\n",
       "3          4   4  16  208  220  3472  3484  3676  3688\n",
       "4          5   5  17  209  221  3473  3485  3677  3689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List data filenames\n",
    "rock_type = 'BrSS'                                                                           #update, options: BrSS, BSS, KLS\n",
    "model = 'pinn_loss'                                                                        #update, options: pinn_loss, pinn_lambda, analytical\n",
    "folder = \"sim_results_predicted\"\n",
    "level = '2'                                                             \n",
    "# For Filtering\n",
    "filter_data = 'false' # when used there is an issue in data upscaling                      #update\n",
    "dpp = 5 # delta [%] in porosity   (5 should be best)\n",
    "##\n",
    "##\n",
    "small_cubes_results_file = \"./\"+folder+\"/\"+rock_type+\"_300_kxyz_results_\"+model\n",
    "large_cubes_results_file = \"./\"+folder+\"/\"+rock_type+\"_600_kxyz_results\"\n",
    "large_small_cubes_map_info_file = \"./\"+folder+\"/\"+rock_type+\"_600_300_map_info\"\n",
    "##\n",
    "##\n",
    "# Load data files\n",
    "large_cubes_results = pd.read_csv(large_cubes_results_file+\".csv\")\n",
    "small_cubes_results = pd.read_csv(small_cubes_results_file+\".csv\")\n",
    "cubes_map_info = pd.read_csv(large_small_cubes_map_info_file+\".csv\")\n",
    "##\n",
    "# Prepare data\n",
    "large_cubes_results = large_cubes_results.drop(columns=['M. time[s]', 'S. Time[s]'])\n",
    "small_cubes_results = small_cubes_results.drop(columns=['M. time[s]', 'S. Time[s]'])\n",
    "cubes_map_info = cubes_map_info.astype({'c1': 'int', 'c2': 'int', 'c3': 'int', 'c4': 'int','c5': 'int', 'c6': 'int', 'c7': 'int', 'c8': 'int'})\n",
    "##\n",
    "# List data heads\n",
    "display(small_cubes_results.head()) \n",
    "display(large_cubes_results.head())\n",
    "display(cubes_map_info.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of large cubes duplicates: 0\n",
      "Number of small cubes duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "##\n",
    "# Filter data\n",
    "if filter_data == 'true':\n",
    "    # Filter data from ep > 0.5 & k < 0\n",
    "    # small cubes data\n",
    "    p = small_cubes_results['Porosity']\n",
    "    ep = small_cubes_results['Eff. Porosity']\n",
    "    small_cubes_results['dpp'] = np.abs(p-ep)*100/p\n",
    "    small_cubes_results = small_cubes_results[(small_cubes_results['dpp'] < dpp)]\n",
    "    small_cubes_results = small_cubes_results.drop(columns=['dpp'])\n",
    "    #\n",
    "    small_cubes_results = small_cubes_results[(small_cubes_results['Eff. Porosity'] < 0.5)]\n",
    "    small_cubes_results = small_cubes_results[(small_cubes_results['K(x)[D]'] > 0)]\n",
    "    small_cubes_results = small_cubes_results[(small_cubes_results['K(y)[D]'] > 0)]\n",
    "    small_cubes_results = small_cubes_results[(small_cubes_results['K(z)[D]'] > 0)]\n",
    "    # large cubes data\n",
    "    P = large_cubes_results['Porosity']\n",
    "    EP = large_cubes_results['Eff. Porosity']\n",
    "    large_cubes_results['dpp'] = np.abs(P-EP)*100/P\n",
    "    large_cubes_results = large_cubes_results[(large_cubes_results['dpp'] < dpp)]\n",
    "    large_cubes_results = large_cubes_results.drop(columns=['dpp'])\n",
    "    \n",
    "    #\n",
    "    large_cubes_results = large_cubes_results[(large_cubes_results['Eff. Porosity'] < 0.5)]\n",
    "    large_cubes_results = large_cubes_results[(large_cubes_results['K(x)[D]'] > 0)]\n",
    "    large_cubes_results = large_cubes_results[(large_cubes_results['K(y)[D]'] > 0)]\n",
    "    large_cubes_results = large_cubes_results[(large_cubes_results['K(z)[D]'] > 0)]\n",
    "##\n",
    "##\n",
    "# Check duplicate data\n",
    "large_cubes_results_duplicates_sum = large_cubes_results['case-name'].duplicated().sum()\n",
    "small_cubes_results_duplicates_sum = small_cubes_results['case-name'].duplicated().sum()\n",
    "large_cubes_results_duplicates = large_cubes_results.loc[large_cubes_results['case-name'].duplicated(), :]\n",
    "small_cubes_results_duplicates = small_cubes_results.loc[small_cubes_results['case-name'].duplicated(), :]\n",
    "# Print Summary\n",
    "print(\"Number of large cubes duplicates: \"+str(large_cubes_results_duplicates_sum))\n",
    "print(\"Number of small cubes duplicates: \"+str(small_cubes_results_duplicates_sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case-name</th>\n",
       "      <th>P</th>\n",
       "      <th>EP</th>\n",
       "      <th>KX</th>\n",
       "      <th>KY</th>\n",
       "      <th>KZ</th>\n",
       "      <th>c1</th>\n",
       "      <th>p1</th>\n",
       "      <th>ep1</th>\n",
       "      <th>kx1</th>\n",
       "      <th>...</th>\n",
       "      <th>ep7</th>\n",
       "      <th>kx7</th>\n",
       "      <th>ky7</th>\n",
       "      <th>kz7</th>\n",
       "      <th>c8</th>\n",
       "      <th>p8</th>\n",
       "      <th>ep8</th>\n",
       "      <th>kx8</th>\n",
       "      <th>ky8</th>\n",
       "      <th>kz8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203290</td>\n",
       "      <td>0.195858</td>\n",
       "      <td>2.0640</td>\n",
       "      <td>2.3188</td>\n",
       "      <td>2.2892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192573</td>\n",
       "      <td>0.186276</td>\n",
       "      <td>1.37052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>3.33719</td>\n",
       "      <td>2.62803</td>\n",
       "      <td>2.82594</td>\n",
       "      <td>3685</td>\n",
       "      <td>0.194219</td>\n",
       "      <td>0.191112</td>\n",
       "      <td>2.14644</td>\n",
       "      <td>2.23167</td>\n",
       "      <td>1.66391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.200972</td>\n",
       "      <td>0.193614</td>\n",
       "      <td>2.0488</td>\n",
       "      <td>2.2914</td>\n",
       "      <td>2.2151</td>\n",
       "      <td>3</td>\n",
       "      <td>0.193239</td>\n",
       "      <td>0.19098</td>\n",
       "      <td>1.68808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219431</td>\n",
       "      <td>2.75877</td>\n",
       "      <td>2.1629</td>\n",
       "      <td>2.45725</td>\n",
       "      <td>3687</td>\n",
       "      <td>0.190157</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>1.80108</td>\n",
       "      <td>2.31731</td>\n",
       "      <td>1.37947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.201519</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>2.0148</td>\n",
       "      <td>2.2800</td>\n",
       "      <td>2.1974</td>\n",
       "      <td>5</td>\n",
       "      <td>0.202113</td>\n",
       "      <td>0.199161</td>\n",
       "      <td>1.656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212136</td>\n",
       "      <td>2.22447</td>\n",
       "      <td>2.3319</td>\n",
       "      <td>3.158</td>\n",
       "      <td>3689</td>\n",
       "      <td>0.195983</td>\n",
       "      <td>0.19269</td>\n",
       "      <td>1.88412</td>\n",
       "      <td>2.03475</td>\n",
       "      <td>1.38909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.202835</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>2.0999</td>\n",
       "      <td>2.3295</td>\n",
       "      <td>2.2449</td>\n",
       "      <td>19</td>\n",
       "      <td>0.189896</td>\n",
       "      <td>0.187198</td>\n",
       "      <td>1.43234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216275</td>\n",
       "      <td>3.02147</td>\n",
       "      <td>1.94319</td>\n",
       "      <td>1.98856</td>\n",
       "      <td>3703</td>\n",
       "      <td>0.190749</td>\n",
       "      <td>0.185929</td>\n",
       "      <td>1.5157</td>\n",
       "      <td>2.24921</td>\n",
       "      <td>1.96677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.201671</td>\n",
       "      <td>0.193953</td>\n",
       "      <td>2.0351</td>\n",
       "      <td>2.2749</td>\n",
       "      <td>2.1776</td>\n",
       "      <td>21</td>\n",
       "      <td>0.191968</td>\n",
       "      <td>0.188707</td>\n",
       "      <td>1.44846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214281</td>\n",
       "      <td>2.02708</td>\n",
       "      <td>2.24935</td>\n",
       "      <td>2.49396</td>\n",
       "      <td>3705</td>\n",
       "      <td>0.183912</td>\n",
       "      <td>0.180902</td>\n",
       "      <td>1.35623</td>\n",
       "      <td>1.83163</td>\n",
       "      <td>1.60844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case-name         P        EP      KX      KY      KZ  c1        p1  \\\n",
       "0          1  0.203290  0.195858  2.0640  2.3188  2.2892   1  0.192573   \n",
       "1          3  0.200972  0.193614  2.0488  2.2914  2.2151   3  0.193239   \n",
       "2          5  0.201519  0.193641  2.0148  2.2800  2.1974   5  0.202113   \n",
       "3          7  0.202835  0.195556  2.0999  2.3295  2.2449  19  0.189896   \n",
       "4          9  0.201671  0.193953  2.0351  2.2749  2.1776  21  0.191968   \n",
       "\n",
       "        ep1      kx1  ...       ep7      kx7      ky7      kz7    c8  \\\n",
       "0  0.186276  1.37052  ...  0.219171  3.33719  2.62803  2.82594  3685   \n",
       "1   0.19098  1.68808  ...  0.219431  2.75877   2.1629  2.45725  3687   \n",
       "2  0.199161    1.656  ...  0.212136  2.22447   2.3319    3.158  3689   \n",
       "3  0.187198  1.43234  ...  0.216275  3.02147  1.94319  1.98856  3703   \n",
       "4  0.188707  1.44846  ...  0.214281  2.02708  2.24935  2.49396  3705   \n",
       "\n",
       "         p8       ep8      kx8      ky8      kz8  \n",
       "0  0.194219  0.191112  2.14644  2.23167  1.66391  \n",
       "1  0.190157  0.186364  1.80108  2.31731  1.37947  \n",
       "2  0.195983   0.19269  1.88412  2.03475  1.38909  \n",
       "3  0.190749  0.185929   1.5157  2.24921  1.96677  \n",
       "4  0.183912  0.180902  1.35623  1.83163  1.60844  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cubes has no complete results: \n",
      "Empty DataFrame\n",
      "Columns: [case-name, P, EP, KX, KY, KZ, c1, p1, ep1, kx1, ky1, kz1, c2, p2, ep2, kx2, ky2, kz2, c3, p3, ep3, kx3, ky3, kz3, c4, p4, ep4, kx4, ky4, kz4, c5, p5, ep5, kx5, ky5, kz5, c6, p6, ep6, kx6, ky6, kz6, c7, p7, ep7, kx7, ky7, kz7, c8, p8, ep8, kx8, ky8, kz8]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge large cubes with map\n",
    "merge_large_map = pd.merge(large_cubes_results, cubes_map_info, on = 'case-name', how = 'left') \n",
    "#\n",
    "# Combine data\n",
    "num_large_cubes = len(large_cubes_results)\n",
    "combined_data = pd.DataFrame(columns=['case-name', 'P', 'EP','KX','KY','KZ', \n",
    "                                      'c1', 'p1', 'ep1', 'kx1', 'ky1', 'kz1',\n",
    "                                      'c2', 'p2', 'ep2', 'kx2', 'ky2', 'kz2',\n",
    "                                      'c3', 'p3', 'ep3', 'kx3', 'ky3', 'kz3',\n",
    "                                      'c4', 'p4', 'ep4', 'kx4', 'ky4', 'kz4',\n",
    "                                      'c5', 'p5', 'ep5', 'kx5', 'ky5', 'kz5',\n",
    "                                      'c6', 'p6', 'ep6', 'kx6', 'ky6', 'kz6',\n",
    "                                      'c7', 'p7', 'ep7', 'kx7', 'ky7', 'kz7',\n",
    "                                      'c8', 'p8', 'ep8', 'kx8', 'ky8', 'kz8',], index=range(num_large_cubes))\n",
    "#\n",
    "# Combine data\n",
    "#\n",
    "# load large cubes results\n",
    "combined_data['case-name'] = merge_large_map['case-name']\n",
    "combined_data['P'] = merge_large_map['Porosity']\n",
    "combined_data['EP'] = merge_large_map['Eff. Porosity']\n",
    "combined_data['KX'] = merge_large_map['K(x)[D]']\n",
    "combined_data['KY'] = merge_large_map['K(y)[D]']\n",
    "combined_data['KZ'] = merge_large_map['K(z)[D]']\n",
    "combined_data['c1'] = merge_large_map['c1']\n",
    "combined_data['c2'] = merge_large_map['c2']\n",
    "combined_data['c3'] = merge_large_map['c3']\n",
    "combined_data['c4'] = merge_large_map['c4']\n",
    "combined_data['c5'] = merge_large_map['c5']\n",
    "combined_data['c6'] = merge_large_map['c6']\n",
    "combined_data['c7'] = merge_large_map['c7']\n",
    "combined_data['c8'] = merge_large_map['c8']\n",
    "#\n",
    "combined_data.head() \n",
    "#\n",
    "# get small cubes lists\n",
    "c1_list = merge_large_map['c1']\n",
    "c2_list = merge_large_map['c2']\n",
    "c3_list = merge_large_map['c3']\n",
    "c4_list = merge_large_map['c4']\n",
    "c5_list = merge_large_map['c5']\n",
    "c6_list = merge_large_map['c6']\n",
    "c7_list = merge_large_map['c7']\n",
    "c8_list = merge_large_map['c8']\n",
    "#\n",
    "# loop to build combined data\n",
    "m = 1\n",
    "for list in ([c1_list, c2_list, c3_list, c4_list, c5_list, c6_list, c7_list, c8_list]):\n",
    "    n = 0\n",
    "    for i in list:\n",
    "        p = \"p\"+str(m)\n",
    "        ep = \"ep\"+str(m)\n",
    "        kx = \"kx\"+str(m)\n",
    "        ky = \"ky\"+str(m)\n",
    "        kz = \"kz\"+str(m)\n",
    "        condition = str(i in small_cubes_results['case-name'].values)\n",
    "        if condition == \"True\":\n",
    "            combined_data.loc[n, p] = np.array(small_cubes_results.loc[small_cubes_results['case-name'] == i, 'Porosity'])[0]\n",
    "            combined_data.loc[n, ep] = np.array(small_cubes_results.loc[small_cubes_results['case-name'] == i, 'Eff. Porosity'])[0]\n",
    "            combined_data.loc[n, kx] = np.array(small_cubes_results.loc[small_cubes_results['case-name'] == i, 'K(x)[D]'])[0]\n",
    "            combined_data.loc[n, ky] = np.array(small_cubes_results.loc[small_cubes_results['case-name'] == i, 'K(y)[D]'])[0]\n",
    "            combined_data.loc[n, kz] = np.array(small_cubes_results.loc[small_cubes_results['case-name'] == i, 'K(z)[D]'])[0]\n",
    "        n = n + 1\n",
    "    m = m + 1   \n",
    "#\n",
    "# List data head\n",
    "display(combined_data.head())\n",
    "##\n",
    "##\n",
    "## Filter Data from NAN\n",
    "#\n",
    "# look for cubes with no avaible results\n",
    "nan_rows = combined_data[combined_data.isna().any(axis=1)]\n",
    "print(\"The following cubes has no complete results: \\n\" + str(nan_rows))\n",
    "#\n",
    "# Filter data from nans \n",
    "combined_data_red = combined_data.dropna()\n",
    "nan_rows_red = combined_data_red[combined_data_red.isna().any(axis=1)]\n",
    "#\n",
    "# Filter data from zeros\n",
    "combined_data_red = combined_data_red[combined_data_red.loc[:]!=0].dropna()\n",
    "#\n",
    "# Filter data from negative values\n",
    "for cols in combined_data_red.columns.tolist()[1:]:\n",
    "    combined_data_red = combined_data_red[combined_data_red[cols] > 0]\n",
    "#\n",
    "# Filter data from ep > 0.5\n",
    "epr = 0.5\n",
    "combined_data_red = combined_data_red[(combined_data_red.EP < epr)\n",
    "                                    & (combined_data_red.ep1 < epr)\n",
    "                                    & (combined_data_red.ep2 < epr)\n",
    "                                    & (combined_data_red.ep3 < epr)\n",
    "                                    & (combined_data_red.ep4 < epr)\n",
    "                                    & (combined_data_red.ep5 < epr)\n",
    "                                    & (combined_data_red.ep6 < epr)\n",
    "                                    & (combined_data_red.ep7 < epr)\n",
    "                                    & (combined_data_red.ep8 < epr)]\n",
    "#\n",
    "# List data head\n",
    "# display(combined_data_red.head())\n",
    "##\n",
    "##\n",
    "# Rotate data\n",
    "combined_data_3dir = data_rotate(combined_data_red)\n",
    "##\n",
    "##\n",
    "# Save Data files\n",
    "combined_data.to_csv('./data/'+rock_type+'_compiled_data_level_'+level+'_'+model+'.csv', index=False)\n",
    "# combined_data_red.to_csv('./data/'+rock_type+'_compiled_data_red_level_'+level+'_'+model+'.csv', index=False)\n",
    "combined_data_3dir.to_csv('./data/'+rock_type+'_compiled_data_3dir_level_'+level+'_'+model+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('tensorflow-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "181f340e2df7e34e778a2366a317e676f39d4ffc23bddca1ebda0b79fed9b5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
